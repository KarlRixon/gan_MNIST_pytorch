{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow, imsave\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "n_epoch = 40\n",
    "z_dim = 100\n",
    "mnist_dim = 784\n",
    "lr = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='../data/', train=True, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Discriminator for MNIST\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel=1, num_classes=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # 28 -> 14\n",
    "            nn.Conv2d(in_channel, 512, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # 14 -> 7\n",
    "            nn.Conv2d(512, 256, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # 7 -> 4\n",
    "            nn.Conv2d(256, 128, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.AvgPool2d(4),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            # reshape input, 128 -> 1\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        y_ = self.conv(x)\n",
    "        y_ = y_.view(y_.size(0), -1)\n",
    "        y_ = self.fc(y_)\n",
    "        return y_\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Generator for MNIST\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=100, num_classes=784):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 4*4*512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            # input: 4 by 4, output: 7 by 7\n",
    "            nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # input: 7 by 7, output: 14 by 14\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # input: 14 by 14, output: 28 by 28\n",
    "            nn.ConvTranspose2d(128, 1, 4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_ = self.fc(x)\n",
    "        y_ = y_.view(y_.size(0), 512, 4, 4)\n",
    "        y_ = self.conv(y_)\n",
    "        return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=8192, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv): Sequential(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2)\n",
       "    (9): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "# optimizer\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "D_real = torch.ones([bs, 1]).to(device) # Discriminator Label to real\n",
    "D_fake = torch.zeros([bs, 1]).to(device) # Discriminator Label to fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_losses, G_losses = [], []\n",
    "real_scores, fake_scores = [], []\n",
    "fixed_noise = Variable(torch.randn(bs, z_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1/40]batch[99/937]: loss_d: 0.753, loss_g: 1.313, D(x): 0.698, D(G(z)): 0.322\n",
      "epoch[1/40]batch[199/937]: loss_d: 0.550, loss_g: 2.006, D(x): 0.832, D(G(z)): 0.283\n",
      "epoch[1/40]batch[299/937]: loss_d: 0.449, loss_g: 2.007, D(x): 0.776, D(G(z)): 0.176\n",
      "epoch[1/40]batch[399/937]: loss_d: 0.686, loss_g: 1.234, D(x): 0.554, D(G(z)): 0.078\n",
      "epoch[1/40]batch[499/937]: loss_d: 0.298, loss_g: 2.094, D(x): 0.850, D(G(z)): 0.123\n",
      "epoch[1/40]batch[599/937]: loss_d: 0.186, loss_g: 3.230, D(x): 0.941, D(G(z)): 0.117\n",
      "epoch[1/40]batch[699/937]: loss_d: 0.197, loss_g: 2.490, D(x): 0.960, D(G(z)): 0.142\n",
      "epoch[1/40]batch[799/937]: loss_d: 0.557, loss_g: 2.456, D(x): 0.610, D(G(z)): 0.030\n",
      "epoch[1/40]batch[899/937]: loss_d: 0.030, loss_g: 4.401, D(x): 0.985, D(G(z)): 0.016\n",
      "epoch[2/40]batch[99/937]: loss_d: 0.028, loss_g: 4.431, D(x): 0.989, D(G(z)): 0.016\n",
      "epoch[2/40]batch[199/937]: loss_d: 0.618, loss_g: 2.195, D(x): 0.861, D(G(z)): 0.364\n",
      "epoch[2/40]batch[299/937]: loss_d: 0.152, loss_g: 2.789, D(x): 0.915, D(G(z)): 0.060\n",
      "epoch[2/40]batch[399/937]: loss_d: 0.314, loss_g: 2.548, D(x): 0.920, D(G(z)): 0.202\n",
      "epoch[2/40]batch[499/937]: loss_d: 0.505, loss_g: 1.725, D(x): 0.694, D(G(z)): 0.082\n",
      "epoch[2/40]batch[599/937]: loss_d: 0.166, loss_g: 1.618, D(x): 0.917, D(G(z)): 0.075\n",
      "epoch[2/40]batch[699/937]: loss_d: 0.164, loss_g: 2.746, D(x): 0.935, D(G(z)): 0.091\n",
      "epoch[2/40]batch[799/937]: loss_d: 0.183, loss_g: 3.046, D(x): 0.907, D(G(z)): 0.080\n",
      "epoch[2/40]batch[899/937]: loss_d: 0.023, loss_g: 4.488, D(x): 0.990, D(G(z)): 0.013\n",
      "epoch[3/40]batch[99/937]: loss_d: 0.524, loss_g: 1.836, D(x): 0.646, D(G(z)): 0.045\n",
      "epoch[3/40]batch[199/937]: loss_d: 0.235, loss_g: 2.191, D(x): 0.859, D(G(z)): 0.075\n",
      "epoch[3/40]batch[299/937]: loss_d: 0.229, loss_g: 2.148, D(x): 0.919, D(G(z)): 0.130\n",
      "epoch[3/40]batch[399/937]: loss_d: 0.148, loss_g: 2.777, D(x): 0.926, D(G(z)): 0.066\n",
      "epoch[3/40]batch[499/937]: loss_d: 0.155, loss_g: 2.248, D(x): 0.878, D(G(z)): 0.021\n",
      "epoch[3/40]batch[599/937]: loss_d: 0.163, loss_g: 3.091, D(x): 0.927, D(G(z)): 0.080\n",
      "epoch[3/40]batch[699/937]: loss_d: 0.115, loss_g: 2.735, D(x): 0.936, D(G(z)): 0.047\n",
      "epoch[3/40]batch[799/937]: loss_d: 0.199, loss_g: 2.666, D(x): 0.902, D(G(z)): 0.087\n",
      "epoch[3/40]batch[899/937]: loss_d: 0.161, loss_g: 2.742, D(x): 0.957, D(G(z)): 0.109\n",
      "epoch[4/40]batch[99/937]: loss_d: 0.155, loss_g: 3.579, D(x): 0.952, D(G(z)): 0.098\n",
      "epoch[4/40]batch[199/937]: loss_d: 0.118, loss_g: 3.178, D(x): 0.939, D(G(z)): 0.051\n",
      "epoch[4/40]batch[299/937]: loss_d: 0.178, loss_g: 2.824, D(x): 0.916, D(G(z)): 0.083\n",
      "epoch[4/40]batch[399/937]: loss_d: 0.153, loss_g: 4.544, D(x): 0.981, D(G(z)): 0.123\n",
      "epoch[4/40]batch[499/937]: loss_d: 0.523, loss_g: 1.588, D(x): 0.656, D(G(z)): 0.047\n",
      "epoch[4/40]batch[599/937]: loss_d: 0.083, loss_g: 3.186, D(x): 0.958, D(G(z)): 0.038\n",
      "epoch[4/40]batch[699/937]: loss_d: 0.169, loss_g: 3.506, D(x): 0.928, D(G(z)): 0.085\n",
      "epoch[4/40]batch[799/937]: loss_d: 0.085, loss_g: 2.985, D(x): 0.934, D(G(z)): 0.016\n",
      "epoch[4/40]batch[899/937]: loss_d: 0.177, loss_g: 2.749, D(x): 0.884, D(G(z)): 0.048\n",
      "epoch[5/40]batch[99/937]: loss_d: 0.170, loss_g: 2.851, D(x): 0.942, D(G(z)): 0.101\n",
      "epoch[5/40]batch[199/937]: loss_d: 0.083, loss_g: 3.938, D(x): 0.970, D(G(z)): 0.050\n",
      "epoch[5/40]batch[299/937]: loss_d: 0.084, loss_g: 4.427, D(x): 0.967, D(G(z)): 0.049\n",
      "epoch[5/40]batch[399/937]: loss_d: 0.152, loss_g: 3.442, D(x): 0.889, D(G(z)): 0.027\n",
      "epoch[5/40]batch[499/937]: loss_d: 0.156, loss_g: 2.786, D(x): 0.958, D(G(z)): 0.103\n",
      "epoch[5/40]batch[599/937]: loss_d: 0.105, loss_g: 3.067, D(x): 0.920, D(G(z)): 0.020\n",
      "epoch[5/40]batch[699/937]: loss_d: 0.226, loss_g: 2.703, D(x): 0.896, D(G(z)): 0.105\n",
      "epoch[5/40]batch[799/937]: loss_d: 0.089, loss_g: 3.490, D(x): 0.928, D(G(z)): 0.013\n",
      "epoch[5/40]batch[899/937]: loss_d: 0.258, loss_g: 2.267, D(x): 0.833, D(G(z)): 0.053\n",
      "epoch[6/40]batch[99/937]: loss_d: 0.091, loss_g: 2.914, D(x): 0.984, D(G(z)): 0.070\n",
      "epoch[6/40]batch[199/937]: loss_d: 0.035, loss_g: 4.495, D(x): 0.982, D(G(z)): 0.016\n",
      "epoch[6/40]batch[299/937]: loss_d: 0.070, loss_g: 3.564, D(x): 0.960, D(G(z)): 0.028\n",
      "epoch[6/40]batch[399/937]: loss_d: 0.040, loss_g: 4.723, D(x): 0.987, D(G(z)): 0.026\n",
      "epoch[6/40]batch[499/937]: loss_d: 0.052, loss_g: 3.338, D(x): 0.973, D(G(z)): 0.024\n",
      "epoch[6/40]batch[599/937]: loss_d: 0.123, loss_g: 3.434, D(x): 0.968, D(G(z)): 0.084\n",
      "epoch[6/40]batch[699/937]: loss_d: 0.219, loss_g: 2.919, D(x): 0.872, D(G(z)): 0.067\n",
      "epoch[6/40]batch[799/937]: loss_d: 0.040, loss_g: 3.806, D(x): 0.986, D(G(z)): 0.025\n",
      "epoch[6/40]batch[899/937]: loss_d: 0.033, loss_g: 4.420, D(x): 0.993, D(G(z)): 0.025\n",
      "epoch[7/40]batch[99/937]: loss_d: 0.073, loss_g: 3.886, D(x): 0.970, D(G(z)): 0.040\n",
      "epoch[7/40]batch[199/937]: loss_d: 0.032, loss_g: 4.955, D(x): 0.990, D(G(z)): 0.021\n",
      "epoch[7/40]batch[299/937]: loss_d: 0.139, loss_g: 2.509, D(x): 0.895, D(G(z)): 0.016\n",
      "epoch[7/40]batch[399/937]: loss_d: 1.095, loss_g: 1.537, D(x): 0.843, D(G(z)): 0.542\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epoch+1):\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        # train discriminator on real data\n",
    "        D_output = D(x.to(device))\n",
    "        real_score = torch.mean(D_output)\n",
    "        D_x_loss = criterion(D_output, D_real)\n",
    "        \n",
    "        # train discriminator on fake data\n",
    "        z = torch.randn(bs, z_dim).to(device)\n",
    "        D_output = D(G(z))\n",
    "        fake_score = torch.mean(D_output)\n",
    "        D_z_loss = criterion(D_output, D_fake)\n",
    "        \n",
    "        D_loss = D_x_loss + D_z_loss\n",
    "        D_optimizer.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "        \n",
    "        # train generator\n",
    "        z = torch.randn(bs, z_dim).to(device)\n",
    "        D_output = D(G(z))\n",
    "        G_loss = criterion(D_output, D_real)\n",
    "        D_optimizer.zero_grad()\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 99:\n",
    "            D_losses.append(D_loss)\n",
    "            G_losses.append(G_loss)\n",
    "            real_scores.append(real_score)\n",
    "            fake_scores.append(fake_score)\n",
    "            print('epoch[%d/%d]batch[%d/%d]: loss_d: %.3f, loss_g: %.3f, D(x): %.3f, D(G(z)): %.3f' %\n",
    "                 (epoch, n_epoch, batch_idx, len(train_loader), D_loss.item(), G_loss.item(), real_score.item(), fake_score.item()))\n",
    "    \n",
    "    # save models\n",
    "    torch.save(G.state_dict(), './models/dcgan/G.pth')\n",
    "    torch.save(D.state_dict(), './models/dcgan/D.pth')\n",
    "    \n",
    "    # save fake images\n",
    "    with torch.no_grad():\n",
    "        generated = G(fixed_noise)\n",
    "        save_image(generated.view(generated.size(0), 1, 28, 28), './samples/dcgan/sample_%03d.png' % epoch, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(D_losses, label='d loss')\n",
    "plt.plot(G_losses, label='g loss')    \n",
    "plt.legend()\n",
    "plt.savefig('loss_dcgan.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fake_scores, label='fake score')\n",
    "plt.plot(real_scores, label='real score')    \n",
    "plt.legend()\n",
    "plt.savefig('score_dcgan.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
